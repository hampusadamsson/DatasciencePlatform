{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "import pandas\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score, accuracy_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_into_future_target = 2\n",
    "mname = \"RandomForestClassifier\"\n",
    "model_type = \"classifier\"\n",
    "experiment_name = \"stock.classifier\"\n",
    "\n",
    "look_back = [1,2,3,4,5,7,10,15,20,24]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>close</th>\n",
       "      <th>date</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>high</th>\n",
       "      <th>id</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>split_coefficient</th>\n",
       "      <th>symbol</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10.6408</td>\n",
       "      <td>131.13</td>\n",
       "      <td>1998-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.50</td>\n",
       "      <td>MSFT1998-01-02</td>\n",
       "      <td>129.50</td>\n",
       "      <td>129.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>4968500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10.5799</td>\n",
       "      <td>130.38</td>\n",
       "      <td>1998-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.63</td>\n",
       "      <td>MSFT1998-01-05</td>\n",
       "      <td>127.87</td>\n",
       "      <td>131.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>10047200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.6408</td>\n",
       "      <td>131.13</td>\n",
       "      <td>1998-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.00</td>\n",
       "      <td>MSFT1998-01-06</td>\n",
       "      <td>129.25</td>\n",
       "      <td>129.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>8479300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10.5134</td>\n",
       "      <td>129.56</td>\n",
       "      <td>1998-01-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131.19</td>\n",
       "      <td>MSFT1998-01-07</td>\n",
       "      <td>127.50</td>\n",
       "      <td>129.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>7686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10.5897</td>\n",
       "      <td>130.50</td>\n",
       "      <td>1998-01-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.13</td>\n",
       "      <td>MSFT1998-01-08</td>\n",
       "      <td>127.50</td>\n",
       "      <td>128.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>9702400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   adjusted_close   close        date  dividend_amount    high  \\\n",
       "0         10.6408  131.13  1998-01-02              0.0  131.50   \n",
       "1         10.5799  130.38  1998-01-05              0.0  133.63   \n",
       "2         10.6408  131.13  1998-01-06              0.0  133.00   \n",
       "3         10.5134  129.56  1998-01-07              0.0  131.19   \n",
       "4         10.5897  130.50  1998-01-08              0.0  132.13   \n",
       "\n",
       "               id     low    open  split_coefficient symbol    volume  \n",
       "0  MSFT1998-01-02  129.50  129.63                1.0   MSFT   4968500  \n",
       "1  MSFT1998-01-05  127.87  131.25                1.0   MSFT  10047200  \n",
       "2  MSFT1998-01-06  129.25  129.75                1.0   MSFT   8479300  \n",
       "3  MSFT1998-01-07  127.50  129.88                1.0   MSFT   7686600  \n",
       "4  MSFT1998-01-08  127.50  128.63                1.0   MSFT   9702400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\"dataset.csv\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = (df[\"adjusted_close\"].shift(-days_into_future_target) - df[\"adjusted_close\"]) / df[\"adjusted_close\"]\n",
    "targetBin = target.map(lambda x: x>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert df.shape[0] == target.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stockTransformer(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, look_back):\n",
    "        self.days_look_back = look_back\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def _meaning(self, x):\n",
    "        return(True)\n",
    "\n",
    "    def transform(self, tmp, y=None):\n",
    "        #Vi tittar tillbaka {i} dagar\n",
    "        try:\n",
    "            for j in self.days_look_back:\n",
    "                for c in [\"adjusted_close\", \"high\", \"low\", \"open\", \"volume\"]:\n",
    "                    tmp[\"hist_{}_{}\".format(c,j)] = (tmp[c].shift(j) - tmp[c]) / tmp[c]\n",
    "\n",
    "            # Date -> month / day\n",
    "            tmp.date = tmp.date.astype(str)\n",
    "            tmp[\"month\"] = tmp[\"date\"].apply(lambda x : str(x).split(\"-\")[1])\n",
    "            tmp[\"month\"] = tmp[\"month\"].astype(\"int32\")\n",
    "            tmp[\"day\"] = tmp[\"date\"].apply(lambda x : str(x).split(\"-\")[2])\n",
    "            tmp[\"day\"] = tmp[\"day\"].astype(\"int32\")\n",
    "            \n",
    "            tmp = tmp.drop([\"adjusted_close\", \"close\", \"date\", \"dividend_amount\", \"high\", \"id\", \"low\", \"open\", \"split_coefficient\", \"symbol\", \"volume\"], axis=1)\n",
    "            tmp = tmp.replace([np.inf, -np.inf], np.nan)\n",
    "            r = tmp.fillna(-1)\n",
    "            return r\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "        \n",
    "    def predict(self, X, y=None):\n",
    "        return(X)\n",
    "\n",
    "    def score(self, X, y=None):\n",
    "        return(sum(self.predict(X))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = targetBin.fillna(0) # TODO - ta bort NaN från både X/Y\n",
    "X = df\n",
    "\n",
    "X = X[:10000]\n",
    "Y = Y[:10000]\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# print(\"X train shape\\t\", x_train.shape)\n",
    "# print(\"X test shape\\t\", x_test.shape)\n",
    "\n",
    "# for train_index, test_index in tscv.split(X):\n",
    "#     print(Y[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "\n",
    "lr = Pipeline([\n",
    "    ('customTransformer', stockTransformer(look_back)), \n",
    "    (mname, clf)\n",
    "])\n",
    "\n",
    "avg_score = []\n",
    "\n",
    "for inx, s in enumerate(df.symbol.unique()[:3]):\n",
    "    subset = df.loc[df[\"symbol\"] == s]\n",
    "    target = (subset[\"adjusted_close\"].shift(-days_into_future_target) - subset[\"adjusted_close\"]) / subset[\"adjusted_close\"]    \n",
    "    target_bin = target.map(lambda x: x>0)\n",
    "    subset.symbol.fillna(\"MSFT\")\n",
    "    X = subset.fillna(s)\n",
    "    Y = target_bin.fillna(0)\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "        lr.fit(X_train, y_train)\n",
    "        \n",
    "    preds = lr.predict(X)\n",
    "    acc, f1 = eval_metrics(Y, preds)\n",
    "    avg_score.append(acc)\n",
    "    avgscr = sum(avg_score) / (inx+1)\n",
    "    print(\"{}\\t{}\\t{}\".format(s, str(acc)[:4], str(avgscr)[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cc = Counter()\n",
    "cc.update(preds)\n",
    "cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Metrics\n",
    "preds = lr.predict(X)\n",
    "prob = lr.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    acc = accuracy_score(actual, pred)\n",
    "    f1 = f1_score(actual, pred)\n",
    "    return acc, f1\n",
    "\n",
    "acc, f1 = eval_metrics(Y, preds)\n",
    "\n",
    "print(\"{} model - \".format(mname))\n",
    "print(\"  ACC: %s\" % acc)\n",
    "print(\"  F1: %s\" % f1)\n",
    "print(\"  False: %s\" % len([v for v in preds if v == False]))\n",
    "print(\"  True: %s\" % len([v for v in preds if v == True]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hist(predict_prob, fname=\"histogram.png\"):\n",
    "    sns.distplot(prob[:,0], norm_hist=True, bins=20)\n",
    "    plt.title(\"Histogram\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.savefig(fname)\n",
    "    \n",
    "create_hist(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cm(y_pred, y_real, fname=\"cm.png\"):\n",
    "    fig = plt.figure(figsize=(4,4))\n",
    "    cm = confusion_matrix(y_pred, y_real)\n",
    "    sns.heatmap(cm, annot=True, fmt='1d', cbar=False)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.yticks(np.arange(0, 3, 1), [])\n",
    "    plt.xticks(np.arange(0.5, 2, 1), [\"True\", \"False\"])\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.savefig(fname)\n",
    "\n",
    "create_cm(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_roc(y_pred, y_real, fname=\"roc.png\"):\n",
    "    fpr, tpr, _ = roc_curve(y_real, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange',lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "\n",
    "create_roc(preds, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fi(lr, fname=\"feature_importance.png\"):\n",
    "    tmp = lr.steps[1][1] #.feature_importance_\n",
    "    feature_imp = tmp.feature_importances_\n",
    "    features = stockTransformer(look_back).transform(df[:1]).columns\n",
    "    plt.figure(figsize=(5,20))\n",
    "    plt.yticks(range(len(features)), features)\n",
    "    plt.xlabel('Importance factor')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.barh(range(len(feature_imp)), feature_imp)\n",
    "    plt.title('Feature importance graph')\n",
    "    plt.savefig(fname)\n",
    "    plt.show()\n",
    "\n",
    "create_fi(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to MLFLOW\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "mname = \"ADABoost\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    '''\n",
    "        Log parameter, metrics, and model to MLflow\n",
    "    '''    \n",
    "    mlflow.log_param(\"Look-back-days\", look_back)\n",
    "    mlflow.log_param(\"X-train-shape\", X.shape)\n",
    "    mlflow.log_param(\"Days-into-future\", days_into_future_target)\n",
    "    \n",
    "    mlflow.log_metric(\"ACC\", acc)\n",
    "    mlflow.log_metric(\"F1\", f1)\n",
    "    \n",
    "    mlflow.set_tag(\"model\", mname)\n",
    "    mlflow.set_tag(\"model_type\", model_type)\n",
    "    \n",
    "    mlflow.log_artifact(\"cm.png\")\n",
    "    mlflow.log_artifact(\"roc.png\")\n",
    "    mlflow.log_artifact(\"histogram.png\")\n",
    "    mlflow.log_artifact(\"feature_importance.png\")\n",
    "\n",
    "    lr.predict = lr.predict_proba\n",
    "    mlflow.sklearn.log_model(lr, \"model\")\n",
    "    print(\"Model saved to tracking- and artifact server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow - XGboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load training and test datasets\n",
    "# import xgboost as xgb\n",
    "\n",
    "# xgb_model = xgb.train(params={'max_depth': 10}, dtrain=dtrain, num_boost_round=10)\n",
    "# xgb_model_path = \"xgb_model.pth\"\n",
    "# xgb_model.save_model(xgb_model_path)\n",
    "\n",
    "# artifacts = {\n",
    "#     \"xgb_model\": xgb_model_path\n",
    "# }\n",
    "\n",
    "# # Define the model class\n",
    "# import mlflow.pyfunc\n",
    "# class XGBWrapper(mlflow.pyfunc.PythonModel):\n",
    "\n",
    "#     def load_context(self, context):\n",
    "#         import xgboost as xgb\n",
    "#         self.xgb_model = xgb.Booster()\n",
    "#         self.xgb_model.load_model(context.artifacts[\"xgb_model\"])\n",
    "\n",
    "#     def predict(self, context, model_input):\n",
    "#         input_matrix = xgb.DMatrix(model_input.values)\n",
    "#         return self.xgb_model.predict(input_matrix)\n",
    "\n",
    "# # Create a Conda environment for the new MLflow Model that contains the XGBoost library\n",
    "# # as a dependency, as well as the required CloudPickle library\n",
    "# import cloudpickle\n",
    "# conda_env = {\n",
    "#     'channels': ['defaults'],\n",
    "#     'dependencies': [\n",
    "#       'xgboost={}'.format(xgb.__version__),\n",
    "#       'cloudpickle={}'.format(cloudpickle.__version__),\n",
    "#     ],\n",
    "#     'name': 'xgb_env'\n",
    "# }\n",
    "\n",
    "# # Save the MLflow Model\n",
    "# mlflow_pyfunc_model_path = \"xgb_mlflow_pyfunc\"\n",
    "# mlflow.pyfunc.save_model(\n",
    "#         path=mlflow_pyfunc_model_path, python_model=XGBWrapper(), artifacts=artifacts,\n",
    "#         conda_env=conda_env)\n",
    "\n",
    "# # Load the model in `python_function` format\n",
    "# loaded_model = mlflow.pyfunc.load_model(mlflow_pyfunc_model_path)\n",
    "\n",
    "# # Evaluate the model\n",
    "# import pandas as pd\n",
    "# test_predictions = loaded_model.predict(pd.DataFrame(x_test))\n",
    "# print(test_predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
